#!/usr/bin/env python3
"""
AIå¢å¼ºæ™ºèƒ½ç›‘æ§ç³»ç»Ÿ
é›†æˆAIæ¨¡å‹è¿›è¡Œå®æ—¶ç›‘æ§ã€å¼‚å¸¸æ£€æµ‹å’Œæ™ºèƒ½å‘Šè­¦
"""

import asyncio
import json
import time
import logging
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, asdict
from datetime import datetime
import psutil
import aiohttp
from pathlib import Path

from backend.core.base import BaseScript
from backend.core.registry import registry
from backend.scripts.ai_coordinator import AIModelCoordinator


@dataclass
class SystemMetrics:
    """ç³»ç»ŸæŒ‡æ ‡"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    disk_usage: float
    network_io: Dict[str, Any]
    process_count: int
    load_average: tuple

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()


@dataclass
class AIModelMetrics:
    """AIæ¨¡å‹æŒ‡æ ‡"""
    model_name: str
    status: str  # 'online', 'offline', 'degraded'
    response_time: float
    request_count: int
    error_count: int
    last_check: float
    health_score: float  # 0-1

    def __post_init__(self):
        if self.last_check is None:
            self.last_check = time.time()


@dataclass
@dataclass
class Alert:
    """å‘Šè­¦"""
    alert_id: str
    alert_type: str  # 'system', 'ai_model', 'performance', 'security'
    severity: str  # 'low', 'medium', 'high', 'critical'
    title: str
    description: str
    metrics: Dict[str, Any]
    ai_analysis: Optional[Dict[str, Any]] = None
    created_at: Optional[float] = None
    resolved_at: Optional[float] = None
    status: str = 'active'  # 'active', 'resolved', 'acknowledged'

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()
        if self.metrics is None:
            self.metrics = {}


@registry.register("ai_monitor")
class AIMonitorScript(BaseScript):
    """AIå¢å¼ºæ™ºèƒ½ç›‘æ§ç³»ç»Ÿ"""

    name = "ai_monitor"
    description = "AIå¢å¼ºæ™ºèƒ½ç›‘æ§ç³»ç»Ÿ"
    version = "2.0.0"

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        # AIåè°ƒå™¨
        self.ai_coordinator = None

        # ç›‘æ§é…ç½®
        self.config = {
            'check_interval': 30,  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
            'alert_threshold_cpu': 80.0,
            'alert_threshold_memory': 85.0,
            'alert_threshold_disk': 90.0,
            'ai_model_timeout': 10.0,
            'max_alerts_history': 1000,
            'auto_analysis': True,
            'predictive_monitoring': True,
        }

        # ç›‘æ§æ•°æ®
        self.system_metrics: List[SystemMetrics] = []
        self.ai_model_metrics: Dict[str, AIModelMetrics] = {}
        self.active_alerts: Dict[str, Alert] = {}
        self.alerts_history: List[Alert] = []

        # AIæ¨¡å‹é…ç½®
        self.ai_models = {
            'qwen3:8b': {'url': 'http://localhost:11434', 'endpoint': '/api/generate'},
            'llama3.1:8b': {'url': 'http://localhost:11435', 'endpoint': '/api/generate'},
            'deepseek-r1:8b': {'url': 'http://localhost:11436', 'endpoint': '/api/generate'},
            'gpt-oss:20b': {'url': 'http://localhost:11437', 'endpoint': '/api/generate'},
        }

        # HTTPå®¢æˆ·ç«¯
        self.session = None

    async def pre_run(self, **kwargs):
        """åˆå§‹åŒ–"""
        await super().pre_run(**kwargs)

        # åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯
        self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10))

        # åˆå§‹åŒ–AIåè°ƒå™¨
        try:
            self.ai_coordinator = AIModelCoordinator()
            await self.ai_coordinator.initialize()
            self.logger.info("âœ… AIåè°ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ AIåè°ƒå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ai_coordinator = None

    async def run(self, action: str, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œç›‘æ§æ“ä½œ
        """
        try:
            if action == 'start_monitoring':
                result = await self._start_monitoring(**kwargs)
            elif action == 'get_status':
                result = await self._get_system_status()
            elif action == 'analyze_alerts':
                result = await self._analyze_alerts(**kwargs)
            elif action == 'predict_issues':
                result = await self._predict_issues(**kwargs)
            else:
                result = {"status": "error", "error": f"æœªçŸ¥æ“ä½œ: {action}"}

            return result

        except Exception as e:
            self.logger.error(f"ç›‘æ§æ“ä½œå¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}

    async def _start_monitoring(self, **kwargs) -> Dict[str, Any]:
        """å¯åŠ¨ç›‘æ§"""
        try:
            # å¯åŠ¨ç›‘æ§å¾ªç¯
            monitoring_task = asyncio.create_task(self._monitoring_loop())
            alert_check_task = asyncio.create_task(self._alert_check_loop())

            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ç›‘æ§å¯åŠ¨
            await asyncio.sleep(5)

            return {
                "status": "success",
                "message": "AIå¢å¼ºç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨",
                "monitoring_active": True,
                "ai_enhanced": bool(self.ai_coordinator)
            }

        except Exception as e:
            self.logger.error(f"å¯åŠ¨ç›‘æ§å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}

    async def _monitoring_loop(self):
        """ç›‘æ§ä¸»å¾ªç¯"""
        while True:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                await self._collect_system_metrics()

                # æ£€æŸ¥AIæ¨¡å‹çŠ¶æ€
                await self._check_ai_models()

                # æ¸…ç†æ—§æ•°æ®
                self._cleanup_old_data()

                await asyncio.sleep(self.config['check_interval'])

            except Exception as e:
                self.logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(10)

    async def _alert_check_loop(self):
        """å‘Šè­¦æ£€æŸ¥å¾ªç¯"""
        while True:
            try:
                # æ£€æŸ¥ç³»ç»Ÿå‘Šè­¦
                await self._check_system_alerts()

                # æ£€æŸ¥AIæ¨¡å‹å‘Šè­¦
                await self._check_ai_model_alerts()

                # AIå¢å¼ºå‘Šè­¦åˆ†æ
                if self.config['auto_analysis'] and self.ai_coordinator:
                    await self._ai_analyze_alerts()

                await asyncio.sleep(self.config['check_interval'])

            except Exception as e:
                self.logger.error(f"å‘Šè­¦æ£€æŸ¥å¼‚å¸¸: {e}")
                await asyncio.sleep(10)

    async def _collect_system_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)

            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_percent = memory.percent

            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            disk_usage = disk.percent

            # ç½‘ç»œIO
            network = psutil.net_io_counters()
            network_io = {
                'bytes_sent': network.bytes_sent,
                'bytes_recv': network.bytes_recv,
                'packets_sent': network.packets_sent,
                'packets_recv': network.packets_recv
            }

            # è¿›ç¨‹æ•°é‡
            process_count = len(psutil.pids())

            # è´Ÿè½½å¹³å‡å€¼
            load_average = psutil.getloadavg()

            # åˆ›å»ºæŒ‡æ ‡å¯¹è±¡
            metrics = SystemMetrics(
                timestamp=time.time(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                disk_usage=disk_usage,
                network_io=network_io,
                process_count=process_count,
                load_average=load_average
            )

            self.system_metrics.append(metrics)

            # ä¿æŒæœ€è¿‘1000ä¸ªæ•°æ®ç‚¹
            if len(self.system_metrics) > 1000:
                self.system_metrics = self.system_metrics[-1000:]

        except Exception as e:
            self.logger.error(f"æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")

    async def _check_ai_models(self):
        """æ£€æŸ¥AIæ¨¡å‹çŠ¶æ€"""
        for model_name, config in self.ai_models.items():
            try:
                start_time = time.time()

                # å‘é€å¥åº·æ£€æŸ¥è¯·æ±‚
                url = f"{config['url']}/api/tags"
                async with self.session.get(url, timeout=self.config['ai_model_timeout']) as response:
                    response_time = time.time() - start_time

                    if response.status == 200:
                        status = 'online'
                        health_score = 1.0
                    else:
                        status = 'degraded'
                        health_score = 0.5

            except Exception as e:
                response_time = time.time() - start_time
                status = 'offline'
                health_score = 0.0
                self.logger.warning(f"AIæ¨¡å‹ {model_name} æ£€æŸ¥å¤±è´¥: {e}")

            # æ›´æ–°æˆ–åˆ›å»ºæŒ‡æ ‡
            if model_name not in self.ai_model_metrics:
                self.ai_model_metrics[model_name] = AIModelMetrics(
                    model_name=model_name,
                    status=status,
                    response_time=response_time,
                    request_count=1,
                    error_count=1 if status != 'online' else 0,
                    health_score=health_score
                )
            else:
                metrics = self.ai_model_metrics[model_name]
                metrics.status = status
                metrics.response_time = response_time
                metrics.request_count += 1
                if status != 'online':
                    metrics.error_count += 1
                metrics.health_score = health_score
                metrics.last_check = time.time()

    async def _check_system_alerts(self):
        """æ£€æŸ¥ç³»ç»Ÿå‘Šè­¦"""
        if not self.system_metrics:
            return

        latest = self.system_metrics[-1]

        # CPUä½¿ç”¨ç‡å‘Šè­¦
        if latest.cpu_percent > self.config['alert_threshold_cpu']:
            await self._create_alert(
                alert_type='system',
                severity='high' if latest.cpu_percent > 95 else 'medium',
                title=f'CPUä½¿ç”¨ç‡è¿‡é«˜: {latest.cpu_percent:.1f}%',
                description=f'ç³»ç»ŸCPUä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼ {self.config["alert_threshold_cpu"]}%',
                metrics={'cpu_percent': latest.cpu_percent}
            )

        # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
        if latest.memory_percent > self.config['alert_threshold_memory']:
            await self._create_alert(
                alert_type='system',
                severity='high' if latest.memory_percent > 95 else 'medium',
                title=f'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {latest.memory_percent:.1f}%',
                description=f'ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼ {self.config["alert_threshold_memory"]}%',
                metrics={'memory_percent': latest.memory_percent}
            )

        # ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦
        if latest.disk_usage > self.config['alert_threshold_disk']:
            await self._create_alert(
                alert_type='system',
                severity='critical',
                title=f'ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {latest.disk_usage:.1f}%',
                description=f'ç³»ç»Ÿç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼ {self.config["alert_threshold_disk"]}%',
                metrics={'disk_usage': latest.disk_usage}
            )

    async def _check_ai_model_alerts(self):
        """æ£€æŸ¥AIæ¨¡å‹å‘Šè­¦"""
        for model_name, metrics in self.ai_model_metrics.items():
            # ç¦»çº¿å‘Šè­¦
            if metrics.status == 'offline':
                await self._create_alert(
                    alert_type='ai_model',
                    severity='high',
                    title=f'AIæ¨¡å‹ç¦»çº¿: {model_name}',
                    description=f'AIæ¨¡å‹ {model_name} å¤„äºç¦»çº¿çŠ¶æ€',
                    metrics={'model_name': model_name, 'status': metrics.status}
                )

            # å“åº”æ—¶é—´è¿‡é•¿å‘Šè­¦
            if metrics.response_time > 5.0:  # 5ç§’é˜ˆå€¼
                await self._create_alert(
                    alert_type='ai_model',
                    severity='medium',
                    title=f'AIæ¨¡å‹å“åº”æ…¢: {model_name}',
                    description=f'AIæ¨¡å‹ {model_name} å“åº”æ—¶é—´è¿‡é•¿: {metrics.response_time:.2f}s',
                    metrics={'model_name': model_name, 'response_time': metrics.response_time}
                )

            # é”™è¯¯ç‡è¿‡é«˜å‘Šè­¦
            if metrics.request_count > 10:
                error_rate = metrics.error_count / metrics.request_count
                if error_rate > 0.5:  # 50%é”™è¯¯ç‡
                    await self._create_alert(
                        alert_type='ai_model',
                        severity='high',
                        title=f'AIæ¨¡å‹é”™è¯¯ç‡é«˜: {model_name}',
                        description=f'AIæ¨¡å‹ {model_name} é”™è¯¯ç‡è¿‡é«˜: {error_rate:.2%}',
                        metrics={'model_name': model_name, 'error_rate': error_rate}
                    )

    async def _create_alert(self, alert_type: str, severity: str, title: str,
                           description: str, metrics: Dict[str, Any]):
        """åˆ›å»ºå‘Šè­¦"""
        alert_id = f"alert_{int(time.time())}_{hash(title) % 10000}"

        alert = Alert(
            alert_id=alert_id,
            alert_type=alert_type,
            severity=severity,
            title=title,
            description=description,
            metrics=metrics
        )

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå‘Šè­¦
        existing_alert = None
        for active_alert in self.active_alerts.values():
            if (active_alert.alert_type == alert_type and
                active_alert.title == title and
                active_alert.status == 'active'):
                existing_alert = active_alert
                break

        if existing_alert:
            # æ›´æ–°ç°æœ‰å‘Šè­¦çš„æ—¶é—´æˆ³
            existing_alert.created_at = time.time()
        else:
            # åˆ›å»ºæ–°å‘Šè­¦
            self.active_alerts[alert_id] = alert
            self.logger.warning(f"ğŸš¨ æ–°å‘Šè­¦: {title} ({severity})")

    async def _ai_analyze_alerts(self):
        """AIåˆ†æå‘Šè­¦"""
        if not self.ai_coordinator or not self.active_alerts:
            return

        try:
            # è·å–æ´»è·ƒå‘Šè­¦
            active_alerts = list(self.active_alerts.values())

            # å‡†å¤‡åˆ†ææ•°æ®
            alerts_data = []
            for alert in active_alerts[-10:]:  # åˆ†ææœ€è¿‘10ä¸ªå‘Šè­¦
                alerts_data.append({
                    'type': alert.alert_type,
                    'severity': alert.severity,
                    'title': alert.title,
                    'description': alert.description,
                    'metrics': alert.metrics,
                    'age': time.time() - alert.created_at
                })

            analysis_prompt = f"""
            åˆ†æç³»ç»Ÿå‘Šè­¦æ¨¡å¼ï¼š
            å‘Šè­¦æ•°æ®: {json.dumps(alerts_data, ensure_ascii=False, indent=2)}

            è¯·åˆ†æï¼š
            1. å‘Šè­¦æ¨¡å¼è¯†åˆ«
            2. æ½œåœ¨æ ¹æœ¬åŸå› 
            3. å½±å“è¯„ä¼°
            4. è§£å†³å»ºè®®
            5. é¢„é˜²æªæ–½
            """

            analysis_result = await self.ai_coordinator.run('complex_reasoning', content=analysis_prompt)

            if analysis_result.get('status') == 'success':
                ai_insights = analysis_result.get('result', {})

                # å°†AIåˆ†ææ·»åŠ åˆ°å‘Šè­¦ä¸­
                for alert in active_alerts:
                    if alert.alert_id in self.active_alerts:
                        self.active_alerts[alert.alert_id].ai_analysis = ai_insights

                self.logger.info("âœ… AIå‘Šè­¦åˆ†æå®Œæˆ")

        except Exception as e:
            self.logger.error(f"AIå‘Šè­¦åˆ†æå¤±è´¥: {e}")

    async def _predict_issues(self, **kwargs) -> Dict[str, Any]:
        """é¢„æµ‹æ½œåœ¨é—®é¢˜"""
        if not self.ai_coordinator:
            return {"status": "error", "error": "AIåè°ƒå™¨æœªå¯ç”¨"}

        try:
            # æ”¶é›†å†å²æ•°æ®
            recent_metrics = self.system_metrics[-50:] if len(self.system_metrics) >= 50 else self.system_metrics

            # å‡†å¤‡é¢„æµ‹æ•°æ®
            prediction_data = {
                'system_metrics': [
                    {
                        'cpu': m.cpu_percent,
                        'memory': m.memory_percent,
                        'disk': m.disk_usage,
                        'timestamp': m.timestamp
                    } for m in recent_metrics
                ],
                'ai_models': {
                    name: {
                        'status': metrics.status,
                        'response_time': metrics.response_time,
                        'error_rate': metrics.error_count / metrics.request_count if metrics.request_count > 0 else 0
                    } for name, metrics in self.ai_model_metrics.items()
                },
                'active_alerts': len(self.active_alerts)
            }

            prediction_prompt = f"""
            åŸºäºç›‘æ§æ•°æ®é¢„æµ‹æ½œåœ¨é—®é¢˜ï¼š
            ç›‘æ§æ•°æ®: {json.dumps(prediction_data, ensure_ascii=False, indent=2)}

            è¯·é¢„æµ‹ï¼š
            1. çŸ­æœŸé£é™©ï¼ˆ1å°æ—¶å†…ï¼‰
            2. ä¸­æœŸé£é™©ï¼ˆ24å°æ—¶å†…ï¼‰
            3. é•¿æœŸè¶‹åŠ¿
            4. å»ºè®®çš„é¢„é˜²æªæ–½
            5. èµ„æºä¼˜åŒ–å»ºè®®
            """

            result = await self.ai_coordinator.run('complex_reasoning', content=prediction_prompt)

            return result

        except Exception as e:
            self.logger.error(f"é—®é¢˜é¢„æµ‹å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}

    async def _get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            latest_metrics = self.system_metrics[-1] if self.system_metrics else None

            status = {
                "status": "success",
                "timestamp": time.time(),
                "system": {
                    "cpu_percent": latest_metrics.cpu_percent if latest_metrics else 0,
                    "memory_percent": latest_metrics.memory_percent if latest_metrics else 0,
                    "disk_usage": latest_metrics.disk_usage if latest_metrics else 0,
                    "process_count": latest_metrics.process_count if latest_metrics else 0,
                },
                "ai_models": {
                    name: {
                        "status": metrics.status,
                        "response_time": metrics.response_time,
                        "health_score": metrics.health_score,
                        "last_check": metrics.last_check
                    } for name, metrics in self.ai_model_metrics.items()
                },
                "alerts": {
                    "active_count": len(self.active_alerts),
                    "active_alerts": [
                        {
                            "id": alert.alert_id,
                            "type": alert.alert_type,
                            "severity": alert.severity,
                            "title": alert.title,
                            "created_at": alert.created_at
                        } for alert in list(self.active_alerts.values())[-5:]  # æœ€è¿‘5ä¸ª
                    ]
                },
                "ai_enhanced": bool(self.ai_coordinator)
            }

            return status

        except Exception as e:
            self.logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}

    async def _analyze_alerts(self, **kwargs) -> Dict[str, Any]:
        """åˆ†æå‘Šè­¦æ¨¡å¼"""
        if not self.ai_coordinator:
            return {"status": "error", "error": "AIåè°ƒå™¨æœªå¯ç”¨"}

        try:
            # æ”¶é›†å‘Šè­¦å†å²
            alerts_data = []
            for alert in self.alerts_history[-50:]:  # æœ€è¿‘50ä¸ªå‘Šè­¦
                alerts_data.append({
                    'type': alert.alert_type,
                    'severity': alert.severity,
                    'title': alert.title,
                    'description': alert.description,
                    'duration': (alert.resolved_at - alert.created_at) if alert.resolved_at else (time.time() - alert.created_at),
                    'status': alert.status
                })

            analysis_prompt = f"""
            åˆ†æå‘Šè­¦æ¨¡å¼å’Œè¶‹åŠ¿ï¼š
            å‘Šè­¦å†å²: {json.dumps(alerts_data, ensure_ascii=False, indent=2)}

            è¯·åˆ†æï¼š
            1. å‘Šè­¦ç±»å‹åˆ†å¸ƒ
            2. æ—¶é—´æ¨¡å¼è¯†åˆ«
            3. æ ¹æœ¬åŸå› åˆ†æ
            4. æ”¹è¿›å»ºè®®
            5. é¢„æµ‹æ€§ç»´æŠ¤å»ºè®®
            """

            result = await self.ai_coordinator.run('complex_reasoning', content=analysis_prompt)

            return result

        except Exception as e:
            self.logger.error(f"å‘Šè­¦åˆ†æå¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}

    def _cleanup_old_data(self):
        """æ¸…ç†æ—§æ•°æ®"""
        current_time = time.time()

        # æ¸…ç†30å¤©å‰çš„ç³»ç»ŸæŒ‡æ ‡
        cutoff_time = current_time - (30 * 24 * 60 * 60)  # 30å¤©
        self.system_metrics = [
            m for m in self.system_metrics
            if m.timestamp > cutoff_time
        ]

        # æ¸…ç†å·²è§£å†³çš„æ—§å‘Šè­¦
        resolved_cutoff = current_time - (7 * 24 * 60 * 60)  # 7å¤©
        alerts_to_remove = []
        for alert_id, alert in self.active_alerts.items():
            if alert.status != 'active' and alert.created_at < resolved_cutoff:
                alerts_to_remove.append(alert_id)

        for alert_id in alerts_to_remove:
            if alert_id in self.active_alerts:
                self.alerts_history.append(self.active_alerts[alert_id])
                del self.active_alerts[alert_id]

        # é™åˆ¶å‘Šè­¦å†å²æ•°é‡
        if len(self.alerts_history) > self.config['max_alerts_history']:
            self.alerts_history = self.alerts_history[-self.config['max_alerts_history']:]

    async def post_run(self, result: Dict[str, Any]) -> None:
        """åå¤„ç†"""
        await super().post_run(result)

        if self.session:
            await self.session.close()

        self.logger.info("ğŸ“Š AIå¢å¼ºç›‘æ§ç³»ç»Ÿå·²åœæ­¢")